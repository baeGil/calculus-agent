import asyncio
import sys
import os
from unittest.mock import MagicMock, patch

# Add project root to path
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from backend.agent.state import create_initial_state, AgentState
from backend.agent.nodes import planner_node, parallel_executor_node, synthetic_agent_node
from langchain_core.messages import AIMessage

async def test_parallel_flow():
    print("üöÄ Starting Parallel Flow Verification...")
    
    # 1. Setup Initial State with Mock OCR Text (Simulating 2 images processed)
    state = create_initial_state(session_id="test_session")
    state["ocr_text"] = "[·∫¢nh 1]: B√†i to√°n ƒë·∫°o h√†m...\n\n[·∫¢nh 2]: B√†i to√°n t√≠ch ph√¢n..."
    state["messages"] = []  # No user text, just images
    
    print("\n1Ô∏è‚É£  Testing Planner Node...")
    # Mock LLM for Planner to return 2 questions
    with patch("backend.agent.nodes.get_model") as mock_get_model:
        mock_llm = MagicMock()
        async def mock_planner_response(*args, **kwargs):
            return AIMessage(content="""
        ```json
        {
            "questions": [
                {
                    "id": 1,
                    "content": "T√≠nh ƒë·∫°o h√†m c·ªßa x^2",
                    "type": "direct",
                    "tool_input": null
                },
                {
                    "id": 2,
                    "content": "T√≠nh t√≠ch ph√¢n c·ªßa sin(x)",
                    "type": "wolfram",
                    "tool_input": "integrate sin(x)"
                }
            ]
        }
        ```
        """)
        mock_llm.ainvoke.side_effect = mock_planner_response
        mock_get_model.return_value = mock_llm
        
        state = await planner_node(state)
        
        if state.get("execution_plan"):
            print("‚úÖ Planner identified questions:", len(state["execution_plan"]["questions"]))
            print("   Plan:", state["execution_plan"])
        else:
            print("‚ùå Planner failed to generate plan")
            return

    print("\n2Ô∏è‚É£  Testing Parallel Executor Node...")
    # Mock LLM and Wolfram for Executor
    with patch("backend.agent.nodes.get_model") as mock_get_model, \
         patch("backend.agent.nodes.query_wolfram_alpha", new_callable=MagicMock) as mock_wolfram:
        
        # Mock LLM for Direct Question
        mock_llm = MagicMock()
        async def mock_direct_response(*args, **kwargs):
            return AIMessage(content="ƒê·∫°o h√†m c·ªßa x^2 l√† 2x")
        mock_llm.ainvoke.side_effect = mock_direct_response
        mock_get_model.return_value = mock_llm
        
        # Mock Wolfram for Wolfram Question
        # Note: query_wolfram_alpha is an async function
        async def mock_wolfram_call(query):
            return True, "integral of sin(x) = -cos(x) + C"
        mock_wolfram.side_effect = mock_wolfram_call
        
        state = await parallel_executor_node(state)
        
        results = state.get("question_results", [])
        print(f"‚úÖ Executed {len(results)} questions")
        for res in results:
            status = "‚úÖ" if res.get("result") else "‚ùå"
            print(f"   - Question {res['id']} ({res['type']}): {status} Result: {res.get('result')}")

    print("\n3Ô∏è‚É£  Testing Synthetic Node...")
    # Mock LLM for Synthesizer
    with patch("backend.agent.nodes.get_model") as mock_get_model:
        mock_llm = MagicMock()
        async def mock_synth_response(*args, **kwargs):
            return AIMessage(content="## B√†i 1: ƒê·∫°o h√†m... \n\n Result \n\n---\n\n## B√†i 2: T√≠ch ph√¢n... \n\n Result")
        mock_llm.ainvoke.side_effect = mock_synth_response
        mock_get_model.return_value = mock_llm
        
        state = await synthetic_agent_node(state)
        
        final_resp = state.get("final_response")
        # In multi-question mode, synthetic node MIGHT just format headers if we didn't force LLM usage for synthesis?
        # Actually in my code:
        # if question_results:
        #    combined_response.append(...)
        #    final_response = "\n\n---\n\n".join(...)
        #    return state (IT RETURNS EARLY without calling LLM!)
        
        print("‚úÖ Final Response generated:")
        print("-" * 40)
        print(final_resp)
        print("-" * 40)
        
        if "## B√†i 1" in final_resp and "## B√†i 2" in final_resp:
             print("‚úÖ Output format is CORRECT (Contains '## B√†i 1', '## B√†i 2')")
        else:
             print("‚ùå Output format is INCORRECT")

if __name__ == "__main__":
    asyncio.run(test_parallel_flow())
